{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzR492ApsRfD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'''1. What is a random variable in a probability theory?\n",
        "-> In probability theory, a random variable is a function that assigns a numerical value to each outcome in a sample space of a random experiment.\n",
        "Despite the name, a random variable is not truly \"random\" or \"variable\" in the conventional sense—once the outcome is known, its value is fixed. It's simply a way to map outcomes (which might be complex or abstract) to numbers, enabling mathematical analysis.'''\n",
        "\n",
        "\n",
        "'''2. What are the types of random variable?\n",
        "-> There are two main types:\n",
        "1. Discrete random variable: Takes on a countable number of distinct values (e.g., number of heads in 3 coin tosses).\n",
        "2. Continuous random variable: Takes on values from a continuous range (e.g., height of a person, time until a bus arrives).\n",
        "Despite the name, a random variable is not truly \"random\" or \"variable\" in the conventional sense—once the outcome is known, its value is fixed. It's simply a way to map outcomes (which might be complex or abstract) to numbers, enabling mathematical analysis.'''\n",
        "\n",
        "'''3. What is the difference between discrete and continuous distribution?\n",
        "-> The main difference between discrete and continuous distributions lies in the type of values their random variables can take and how probability is assigned.\n",
        "Discrete Distribution:\n",
        "Type of values\tCountable (e.g., 0, 1, 2, ...)\n",
        "Probability of exact value\tPositive (e.g., P(X = 2) = 0.3)\tZero (P(X = 2)= 0)\n",
        "probability is measured over intervals\n",
        "Example distributions\tBinomial, Poisson, Geometric\tNormal, Exponential, Uniform (continuous), Beta\n",
        "Discrete: Number of defective items in a batch (can be 0, 1, 2, …)\n",
        "Continuous Distribution:\n",
        "Uncountable (e.g., any real number within an interval)\n",
        "Probability function\tProbability Mass Function (PMF)\tProbability Density Function (PDF)\n",
        "Graph appearance\tBar graph (distinct spikes)\tSmooth curve\n",
        "Example variable\tNumber of calls received in an hour\tTime between calls\n",
        "Continuous: The weight of a product (can be 1.001 kg, 1.002 kg, etc.)'''\n",
        "\n",
        "'''4. What are probability distribution functions (PDF)?\n",
        "-> In probability theory, a Probability Distribution Function (PDF) typically refers to a function that describes how the probabilities are distributed over the values of a random variable. The term is most often used with continuous random variables, but the concept also applies to discrete ones in a different form.'''\n",
        "\n",
        "'''5. How do Cumulative functions (CDF) differ from probability distribution functions (PDF)?\n",
        "-> Cumulative Distribution Function (CDF):\n",
        "Denoted as :𝐹(𝑥)F(x)\n",
        "Definition: Gives the probability that a random variable 𝑋\n",
        "X is less than or equal to a certain value:\n",
        "𝐹(𝑥)=𝑃(𝑋≤𝑥)\n",
        "F(x)=P(X≤x)\n",
        "It accumulates probabilities up to x\n",
        "Applies to both continuous and discrete variables\n",
        "Always non-decreasing, and ranges from 0 to 1\n",
        "Probability Distribution Function\n",
        "\n",
        "For continuous variables,this is the Probability Density Function (PDF):\n",
        "𝑓(𝑥)f(x)\n",
        "Describes the relative likelihood of the variable being near 𝑥\n",
        "x\n",
        "\n",
        "Area under the curve between two points gives the probability:\n",
        "\n",
        "𝑃(𝑎𝑋≤𝑏)=∫𝑎𝑏𝑓(𝑥) 𝑑𝑥\n",
        "P(a≤X≤b)=∫ ab f(x)dx\n",
        "Relationship to the CDF:\n",
        "\n",
        "𝐹(x)=∫−∞𝑥𝑓(𝑡) 𝑑𝑡 and\n",
        "𝑓(𝑥) =𝑑𝑑𝑥𝐹(𝑥)\n",
        "F(x)=∫−∞x\n",
        "​\n",
        " f(t)dtandf(x)= dxd F(x)\n",
        "For discrete variables, the equivalent is the Probability Mass Function (PMF)\n",
        "𝑝(𝑥)p(x)\n",
        "\n",
        "Here, the CDF is a step function:\n",
        "𝐹(𝑥)=∑𝑡≤𝑥𝑝(𝑡)\n",
        "F(x)= t≤x∑​ p(t)'''\n",
        "\n",
        "'''6. What is a discrete uniform distribution?\n",
        "-> If a discrete random variable\n",
        "𝑋\n",
        "X can take on\n",
        "𝑛\n",
        "n distinct values\n",
        "𝑥1,𝑥2,...,𝑥𝑛x 1​ ,x 2 ,...,x n\n",
        "​\n",
        " , and each has the same probability, then\n",
        "𝑋\n",
        "X follows a discrete uniform distribution.\n",
        "𝑃(𝑋=𝑥𝑖)=1𝑛for 𝑖=1,2,...,𝑛P(X=x i​ )= n1​ ,for i=1,2,...,n\n",
        "Example:\n",
        "Rolling a fair six-sided die:\n",
        "Possible outcomes:\n",
        "{1,2,3,4,5,6}\n",
        "Each has a probability of\n",
        "1/6\n",
        "This is a discrete uniform distribution.\n",
        "Applications:\n",
        "Games of chance (dice, cards, lotteries)\n",
        "Random sampling\n",
        "Simulations where equal-likelihood events are modeled'''\n",
        "\n",
        "'''7. What are the key properties of Bernouli distribution?\n",
        "-> The Bernoulli distribution is the simplest discrete probability distribution, modeling a single trial with only two outcomes: success (usually 1) and failure (usually 0).\n",
        "Property\tFormula\n",
        "Support\n",
        "PMF\n",
        "Mean (Expected value)\n",
        "Variance\n",
        "Skewness\n",
        "Kurtosis (Excess)\n",
        "Entropy'''\n",
        "\n",
        "'''8. What is the binomial distribution, and how is it used in probability?\n",
        "-> The binomial distribution is a discrete probability distribution that models the number of successes in a fixed number of independent Bernoulli trials, each with the same probability of success.\n",
        "The binomial distribution is used when:\n",
        "There are a fixed number of identical trials\n",
        "Each trial has only two outcomes (success/failure)\n",
        "Trials are independent\n",
        "The probability of success 𝑝\n",
        "p is constant'''\n",
        "\n",
        "''''9. What is the poison distribution and where is it applied?\n",
        "-> The Poisson distribution is a discrete probability distribution that models the number of events occurring in a fixed interval of time or space, when the events happen independently and at a constant average rate.\n",
        "Common Applications:\n",
        "Call centers: number of calls per minute\n",
        "Traffic analysis: cars passing a checkpoint per hour\n",
        "Biology: mutations per DNA strand length\n",
        "Retail: number of customers arriving in a store per hour\n",
        "Natural events: earthquakes in a region over a year\n",
        "The Poisson distribution is particularly useful for modeling rare or random events over time or space.'''\n",
        "\n",
        "'''10. What is a continuous uniform distribution?\n",
        "-> The continuous uniform distribution is a type of probability distribution where all values within a given interval are equally likely. It's the continuous analog of the discrete uniform distribution'''\n",
        "\n",
        "'''11. What are the characteristics of a normal distribution?\n",
        "->  The normal distribution, also known as the Gaussian distribution, is one of the most important and widely used probability distributions in statistics. It describes data that tends to cluster around a central mean value.\n",
        "Characteristic:\n",
        "Shape\tBell-shaped and symmetric about the mean\n",
        "Mean, Median, Mode\tAll are equal and located at the center\n",
        "Symmetry\tPerfectly symmetric around the mean\n",
        "Tails\tExtend infinitely in both directions but never touch the x-axis\n",
        "Parameters\tDefined by two parameters:\n",
        "𝜇,μ (mean): center of the distribution\n",
        "σ (standard deviation): spread of the distribution\n",
        "Inflection Points\tOccur at\n",
        "𝜇\n",
        "±\n",
        "𝜎\n",
        "μ±σ where the curve changes concavity\n",
        "Total Area:\tThe total area under the curve is 1 (i.e., it represents a probability distribution)'''\n",
        "\n",
        "'''12. What is the standard normal distribution,and why is it important?\n",
        "-> The standard normal distribution is a special case of the normal distribution where:\n",
        "The mean 𝜇=0μ=0\n",
        "The standard deviation\n",
        "𝜎=1σ=1\n",
        "It is often denoted by the variable\n",
        "Z, and a random variable that follows this distribution is said to be standard normally distributed, written as:\n",
        "𝑍∼𝑁(0,1)Z∼N(0,1)\n",
        "\n",
        "Importance:\n",
        "​This standardization allows comparison between different normal distributions.\n",
        "Statistical Tables\tMost probability tables (used to find cumulative probabilities) are based on the standard normal distribution.\n",
        "Hypothesis Testing\tMany test statistics (e.g. in z-tests) are evaluated using the standard normal distribution.\n",
        "Confidence Intervals\tCommon confidence levels (like 95%) correspond to critical z-values from the standard normal distribution (e.g., ±1.96).\n",
        "Central Limit Theorem (CLT)\tThe CLT tells us that the sampling distribution of the sample mean approaches a standard normal distribution as sample size increases, even if the population isn't normally distributed.'''\n",
        "\n",
        "'''13. What is the central limit theorem(CLT),why is it critical in statistics?\n",
        "-> The Central Limit Theorem states that:\n",
        "Regardless of the original distribution of the population, the sampling distribution of the sample mean (or sum) approaches a normal distribution as the sample size increases, provided the samples are independent and identically distributed (i.i.d.) and the population has a finite mean and variance.\n",
        "Enables Normal Approximation\n",
        "Allows us to use the normal distribution to approximate probabilities, even when the underlying population is not normal.\n",
        "Justifies Many Statistical Tests\n",
        "Most inferential techniques (e.g., confidence intervals, hypothesis tests) rely on the assumption that sample means are normally distributed — the CLT makes this valid for large samples.\n",
        "Robustness:\tWorks even when the population distribution is skewed, bimodal, or non-normal — as long as the sample size is sufficiently large (often n≥30 is a rule of thumb).\n",
        "Foundation for Sampling Theory\tExplains how and why sample statistics behave predictably, forming the basis of survey analysis and quality control.'''\n",
        "\n",
        "'''14. How does the central limit theorem relate to the normal distribution?\n",
        "->Emergence of Normality:\tThe CLT says that the sampling distribution of the sample mean becomes approximately normal, regardless of the population's original distribution. This is what connects arbitrary data distributions to the normal distribution.\n",
        "Shape of the Sampling Distribution:\tAs the sample size 𝑛\n",
        "n increases, the distribution of 𝑋ˉXˉ\n",
        "(the sample mean) converges to a normal distribution, even if the original population is skewed or non-normal.\n",
        "Standard Normal (Z) Form'''\n",
        "\n",
        "'''15. What is the application of Z statistics in hypothesis testing?\n",
        "-> A Z-statistic measures how many standard deviations a sample statistic (like the sample mean) is from the population parameter under the null hypothesis.\n",
        "Z-Test Type\n",
        "One-sample Z-test for mean\tWhen population 𝜎\n",
        "σ is known\tTesting if the average test score differs from 75\n",
        "Two-sample Z-test for means\tComparing two independent sample means\tComparing average heights of men and women\n",
        "Z-test for proportions\tComparing sample proportion to population proportion\tTesting if 60% of voters support a candidate\n",
        "Two-proportion Z-test\tComparing proportions from two groups\tComparing pass rates from two schools'''\n",
        "\n",
        "'''16. How do you calculate Z-score,and what does it represent?\n",
        "-> A Z-score (also called a standard score) tells you how many standard deviations a data point or sample statistic is from the mean of a distribution. It’s a way to standardize values so they can be compared, even across different distributions.\n",
        "Z-Score Formula:\n",
        "For a single data point\n",
        "𝑥\n",
        "x from a population:\n",
        "\n",
        "𝑍=𝑥−𝜇𝜎Z= σx−μ\n",
        "​\n",
        "Where:\n",
        "𝑥\n",
        "x = observed value\n",
        "𝜇\n",
        "μ = population mean\n",
        "𝜎\n",
        "σ = population standard deviation'''\n",
        "\n",
        "'''17. What are point estimates and interval estimates in statistics?\n",
        "-> Point Estimate:\n",
        "A point estimate is a single value used to estimate a population parameter.A best guess or single-number summary of a population parameter\n",
        "Examples\t- Sample mean\n",
        "𝑋ˉXˉestimates population mean\n",
        "𝜇μ- Sample proportion\n",
        "Limitation\tDoesn’t convey uncertainty — it's just a number without a margin of error\n",
        "Interval Estimate (Confidence Interval)\n",
        "An interval estimate provides a range of values that is likely to contain the population parameter, along with a specified level of confidence (e.g., 95%).\n",
        "A range of values constructed from the sample, within which the true population parameter is expected to lie\n",
        "Form\tTypically written as:\n",
        "Point Estimate±Margin of Error'''\n",
        "\n",
        "'''18. What is the significance of confidence intervals in statistical analysis?\n",
        "-> Significance of Confidence Intervals in Statistical Analysis:\n",
        "A confidence interval (CI) is an important tool in statistical inference that provides a range of plausible values for an unknown population parameter (such as the mean, proportion, etc.) based on sample data. The interval reflects both the point estimate and the uncertainty about the parameter.'''\n",
        "\n",
        "'''19. What is the relationship between a z-score and a confidence interval?\n",
        "-> The z-score and confidence interval (CI) are closely related in statistical analysis — the z-score is used to construct and interpret confidence intervals for population parameters when the data is approximately normally distributed and the population standard deviation is known (or the sample size is large).'''\n",
        "\n",
        "'''20. How are z-scores used to compare different distributions?\n",
        "-> Z-scores are incredibly useful for comparing values from different distributions by standardizing the data. This allows us to assess how far a particular value is from the mean in terms of standard deviations, regardless of the original scale or distribution.\n",
        "Key Benefits of Using Z-Scores for Comparison:\n",
        "Standardization of Data:\n",
        "Z-scores transform values from different distributions into a common scale (the standard normal distribution with a mean of 0 and a standard deviation of 1). This makes it easier to compare data points that come from different scales or units.\n",
        "Comparison Across Distributions:\n",
        "By converting raw scores to z-scores, we can compare values from distributions with different means and standard deviations. For example, comparing test scores from two different exams (one with a mean of 50 and a standard deviation of 10, and the other with a mean of 70 and a standard deviation of 5) can be tricky, but z-scores help us understand where each score stands relative to its own distribution.'''\n",
        "\n",
        "'''21. What are the assumptions for applying the Central Limit Theorem?\n",
        "-> The Central Limit Theorem (CLT) is a fundamental concept in statistics that allows us to make inferences about the population mean based on sample data. However, for the CLT to hold true and for the sampling distribution of the sample mean to approach a normal distribution, certain assumptions need to be met.\n",
        "Here are the key assumptions for the CLT:\n",
        " 1. Random Sampling\n",
        "The data must be obtained through random sampling or an equivalent process to ensure that the sample is representative of the population.\n",
        "This assumption ensures that each observation in the sample is independent and that no bias is introduced into the selection process.\n",
        " 2. Independence\n",
        "The sampled observations must be independent of each other. This means that the outcome of one observation should not influence the outcome of another.\n",
        "Without independence, the CLT doesn’t apply because the assumption of random variation in the sample is violated.\n",
        " 3. Sample Size\n",
        "The sample size 𝑛\n",
        "n should be large enough for the CLT to apply.\n",
        "Rule of Thumb: The larger the sample size, the better the CLT approximation. Generally, a sample size of 30 or more is considered sufficient for the CLT to apply to most cases.\n",
        "If the underlying population distribution is highly skewed or has heavy tails, a larger sample size (e.g., 50 or more) may be required for the CLT to give a good approximation.\n",
        " 4. Population Distribution (Shape of the Data)\n",
        "The CLT works best when the population distribution is not too heavily skewed or not too heavy-tailed.\n",
        "If the population is approximately normal to begin with, the sampling distribution will be approximately normal regardless of the sample size.\n",
        "However, if the population distribution is highly skewed or has outliers, a larger sample size will be needed for the sampling distribution of the mean to approximate normality.\n",
        "For example, if the population distribution is extremely skewed or has extreme outliers, the sample size might need to be much larger (e.g., 50+ samples or more) for the CLT to take effect.\n",
        " 5. Finite Variance\n",
        "The population from which the sample is drawn should have a finite variance (𝜎2σ 2 ).\n",
        "If the population has an infinite variance (as in the case of certain distributions like the Cauchy distribution), the CLT doesn’t apply.\n",
        "Finite variance is needed for the sample means to converge to a normal distribution as the sample size increases.'''\n",
        "\n",
        "'''22. What is the concept of expected value in a probability distribution?\n",
        "-> The expected value (EV) is a key concept in probability and statistics that represents the long-run average outcome of a random variable over many trials. It is sometimes called the mean or mathematical expectation of the distribution.\n",
        "The expected value of a random variable is the weighted average of all possible values it can take, with the weights being their respective probabilities.'''\n",
        "\n",
        "'''23. How does a probability distribution relate to the expected outcome of a random variable?\n",
        "-> The probability distribution of a random variable is a function or model that describes the likelihood of different outcomes that the variable can take. The expected value (or mean) is a specific summary statistic that represents the long-term average outcome or the central tendency of the random variable, based on its probability distribution.\n",
        "In simple terms, the expected value is the average outcome you would expect if you repeated the random process (described by the probability distribution) an infinite number of times.\n",
        "How the Probability Distribution Relates to Expected Outcome\n",
        "Weighted Average of All Outcomes:\n",
        "The probability distribution gives the probability of each possible outcome of a random variable.\n",
        "The expected value (mean) is the weighted average of all possible values of the random variable, where each value is weighted by its probability.\n",
        " For a Discrete Random Variable:\n",
        "The probability distribution of a discrete random variable gives you the set of possible outcomes along with their associated probabilities.\n",
        " For a Continuous Random Variable:\n",
        "For continuous random variables, the probability distribution is described by a probability density function (PDF). The expected value is computed using an integral of the product of the variable's value and its probability density over all possible values.'''\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H2dannpgsSUD"
      }
    }
  ]
}